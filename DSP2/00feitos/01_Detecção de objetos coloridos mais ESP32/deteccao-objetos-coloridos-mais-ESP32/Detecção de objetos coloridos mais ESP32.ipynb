{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNOLOGIA DE SANTA CATARINA \\\n",
    "CAMPUS FLORIANÓPOLIS \\\n",
    "DEPARTAMENTO ACADÊMICO DE ELETRÔNICA \\\n",
    "ENGENHARIA ELETRÔNICA\n",
    "\n",
    "Estudante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de objetos coloridos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de cor HSV com OpenCV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos que no espaço de cor HSV, o canal H (*hue*, matiz) apresenta certa independência em relação à iluminação de um objeto. Essa característica pode ser explorada para a detecção de objetos. Teste o código seguinte.\n",
    "\n",
    "Observe como é obtida a máscara (imagem binária, só preto e branco) e como aplicar uma operação _AND_ para separar na imagem original só os M&Ms azuis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # para instalar: pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado de http://docs.opencv.org/3.2.0/df/d9d/tutorial_py_colorspaces.html\n",
    "\n",
    "frame = cv2.imread(\"mms.jpg\") #obtida de http://blogs.mathworks.com/images/steve/2010/mms.jpg\n",
    "\n",
    "# Convert BGR to HSV\n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "# define range of blue color in HSV\n",
    "blue=100 #importante: faixa da componente H no OpenCV: [0, 179]\n",
    "thres=10\n",
    "lower_blue = np.array([blue-thres,50,50])\n",
    "upper_blue = np.array([blue+thres,255,255])\n",
    "\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "cv2.imshow('frame',frame)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.imshow('res',res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responda\n",
    "1. Na função *cvtColor*, que outras conversões estão disponíveis?\n",
    "\n",
    "\n",
    "2. O que faz a função *inRange*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo da webcam ou ESP32-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você tiver uma câmera (webcam), pode testar o mesmo processo com uma captura direta do sinal de vídeo. Caso contrário, use a câmera da placa **ESP32-CAM**, usando o mesmo processo de configuração do servidor descrito nas atividades anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para Webcam\n",
    "# Adaptado de http://docs.opencv.org/3.2.0/df/d9d/tutorial_py_colorspaces.html\n",
    "import cv2\n",
    "import numpy as np\n",
    "color_to_find=100 #importante: faixa da componente H no OpenCV: [0, 179]\n",
    "thres=10\n",
    "cap = cv2.VideoCapture(0) # para usar webcam\n",
    "while(1):\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # define range of blue color in HSV\n",
    "\n",
    "    lower_blue = np.array([color_to_find-thres,50,50])\n",
    "    upper_blue = np.array([color_to_find+thres,255,255])\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para ESP32-CAM\n",
    "# Adaptado de http://docs.opencv.org/3.2.0/df/d9d/tutorial_py_colorspaces.html e\n",
    "# https://how2electronics.com/color-detection-tracking-with-esp32-cam-opencv/\n",
    "import cv2\n",
    "import numpy as np\n",
    "color_to_find=100 #importante: faixa da componente H no OpenCV: [0, 179]\n",
    "thres=10\n",
    "import urllib.request\n",
    "import numpy as np\n",
    " \n",
    "url='http://192.168.4.1/capture' # para usar ESP32-CAM\n",
    "while(1):\n",
    "    # Take each frame\n",
    "    img_resp=urllib.request.urlopen(url)\n",
    "    imgnp=np.array(bytearray(img_resp.read()),dtype=np.uint8)\n",
    "    frame=cv2.imdecode(imgnp,-1)\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([color_to_find-thres,50,50])\n",
    "    upper_blue = np.array([color_to_find+thres,255,255])\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclua, aqui, um quadro capturado e o resultado. Para isso, você deve gravar as imagens com *imwrite* e incorporar o link com o código mostrado abaixo. Ao enviar seu relatório, inclua as imagens no pacote zip."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "![example](example.png \"Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como exemplo, observe o que obtive com a minha webcam.\n",
    "![webcam-identifica-azul](webcam-identifica-azul.png \"Imagem da webcam com identificação de azul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações morfológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deve ter observado que há ruído na máscara e também balas conectadas, que seriam contadas como um objeto único posteriormente. Uma forma de fazer uma \"limpeza\" é através de operações morfológicas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mascara-anotada](mascara-MMs-anotada.png \"Máscara da imagem M&Ms com anotação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elas são operações baseadas no formato da imagem. Usam um *kernel* ou elemento estruturante que define a operação. Os operadores básicos são erosão e dilatação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosão\n",
    "\n",
    "A ideia básica da erosão é retirar os pixels que estão nas bordas do objeto (objeto é o que está em branco, ou seja, com intensidade 1).\n",
    "\n",
    "O elemento estruturante desliza sobre a imagem, como na convolução 2D. Um pixel na imagem resultado será 1 se todos os pixels no kernel forem 1, caso contrário, será erodido (intensidade 0).\n",
    "\n",
    "Desse modo, os pixels próximos às bordas serão descartados. Quanto? Depende do tamanho do kernel. Essa operação é útil, por exemplo, para remover ruídos isolados de pequeno tamanho e separar dois objetos conectados.\n",
    "\n",
    "Há vários exemplos em http://homepages.inf.ed.ac.uk/rbf/HIPR2/erode.htm\n",
    "\n",
    "Observe o exemplo com um elemento estruturante 5x5. Mostre o resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplo de http://docs.opencv.org/3.2.0/d9/d61/tutorial_py_morphological_ops.html\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('j.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "#inclua o código para visualização do resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilatação\n",
    "\n",
    "É o oposto da erosão. Aqui, um pixel resultado será 1 se pelo menos um dos pixels sob análise for 1. Desse modo, há um aumento do tamanho do objeto (aumento da região branca).\n",
    "\n",
    "Dilatação é comumente aplicada após uma operação de erosão para redução de ruído. Também é útil para unir partes de um objeto.\n",
    "\n",
    "Aplique a operação e mostre o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "#inclua o código para visualização do resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contador de balas\n",
    "\n",
    "Com todas essas ferramentas, agora você vai fazer um contador automático de balas.\n",
    "\n",
    "Para contagem das balas, usamos o método de *componentes conectados*, também chamado de *extração de blobs* [https://en.wikipedia.org/wiki/Connected-component_labeling]. A função do OpenCV informa a posição (*centroids* no exemplo) e outros dados (*stats* no exemplo). Para escrever na tela, usa-se a função *putText*.\n",
    "\n",
    "O código a seguir usa a imagem _mms.jpg_ como exemplo. Observe que há:\n",
    "1. Escolha da cor e limiar de detecção\n",
    "2. Erosão para redução de ruídos\n",
    "3. Detecção de elementos pelo algoritmo de componentes conectados\n",
    "4. Apresentação dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado de http://docs.opencv.org/3.2.0/df/d9d/tutorial_py_colorspaces.html\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "frame = cv2.imread(\"mms.jpg\") #obtida de http://blogs.mathworks.com/images/steve/2010/mms.jpg\n",
    "\n",
    "# Convert BGR to HSV\n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "# define range of blue color in HSV\n",
    "blue=100 #importante: faixa da componente H no OpenCV: [0, 179]\n",
    "thres=10\n",
    "lower_blue = np.array([blue-thres,50,50])\n",
    "upper_blue = np.array([blue+thres,255,255])\n",
    "\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(mask,kernel,iterations = 3)\n",
    "#erosion=mask\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(frame,frame, mask= erosion)\n",
    "\n",
    "# find all blobs and label them\n",
    "n, labels, stats, centroids = cv2.connectedComponentsWithStats(erosion)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "for n in range(1,len(stats)): #o primeiro (índice 0) é a imagem toda, então, desconsiderar\n",
    "    cv2.rectangle(res,(stats[n][0],stats[n][1]), (stats[n][0]+stats[n][2],stats[n][1]+stats[n][3]),(255,255,255),2)\n",
    "    cv2.putText(res,str(n),(stats[n][0],stats[n][1]), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.circle(res,(int(centroids[n][0]), int(centroids[n][1])), 3, (0,0,255), -1)\n",
    "    \n",
    "    cv2.putText(frame,str(n),(stats[n][0],stats[n][1]), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.circle(frame,(int(centroids[n][0]), int(centroids[n][1])), 3, (0,0,255), -1)\n",
    "    \n",
    "cv2.putText(frame,'Total: '+str(n),(5, stats[0][3]-5), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "#cv2.imwrite('colorlabels.jpg',res) #para gravar a imagem\n",
    "cv2.imshow('frame',frame)\n",
    "cv2.imshow('mask',erosion)\n",
    "cv2.imshow('labels', res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250.2206512  214.08892625]\n",
      " [166.59677419  47.7983871 ]\n",
      " [355.48837209  85.20930233]\n",
      " [ 96.07714286 107.70857143]\n",
      " [266.70623145 128.13353116]\n",
      " [120.41230769 139.58769231]\n",
      " [279.13256484 161.14409222]\n",
      " [395.03592814 183.24550898]\n",
      " [167.60740741 196.39753086]\n",
      " [142.76315789 220.28362573]\n",
      " [107.45993031 299.02787456]\n",
      " [257.00719424 349.        ]\n",
      " [189.92567568 357.38175676]]\n"
     ]
    }
   ],
   "source": [
    "print(centroids)\n",
    "# que informações são essas? Verifique o retorno da função cv2.connectedComponentsWithStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0    500    428 209983]\n",
      " [   156     36     23     25    372]\n",
      " [   345     74     22     23    344]\n",
      " [    85     97     23     23    350]\n",
      " [   257    117     21     24    337]\n",
      " [   110    129     22     22    325]\n",
      " [   268    150     23     23    347]\n",
      " [   384    173     23     22    334]\n",
      " [   157    184     24     24    405]\n",
      " [   132    210     21     22    342]\n",
      " [    97    289     21     21    287]\n",
      " [   247    339     21     21    278]\n",
      " [   180    348     21     20    296]]\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "# que informações são essas? Verifique o retorno da função cv2.connectedComponentsWithStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MMs-identificados](azul-identificado.jpg \"Imagem M&Ms com contagem dos azuis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de entender o processo, **escolha** uma das imagens anexadas à atividade ou faça uma captura com a sua ESP32-CAM e conte as balas de uma cor específica (escolha também a cor).\n",
    "\n",
    "Seu algoritmo não precisa ter 100% de precisão, mas você deve explicar os possíveis motivos para uma contagem incorreta.\n",
    "\n",
    "Inclua seu código, imagens de resultado, análises e conclusões."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
